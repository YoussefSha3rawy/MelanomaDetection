{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11693,
     "status": "ok",
     "timestamp": 1625871642759,
     "user": {
      "displayName": "Youssef Shaarawy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLBVF6e64J1Txhz0Btn0OOVi4soQV6cBHoy2AxCmo=s64",
      "userId": "04839140160760119561"
     },
     "user_tz": -120
    },
    "id": "Ej8YPilJcmaZ",
    "outputId": "ec7b62b9-7d05-4027-b8d5-085a286d21d2"
   },
   "outputs": [],
   "source": [
    "import shutil,os\n",
    "if not os.path.exists(\"/content/mrcnn\"):\n",
    "    !git clone https://github.com/matterport/Mask_RCNN.git\n",
    "    shutil.move(\"/Mask_RCNN/mrcnn\",\"/\")\n",
    "    !pip install -r \"/content/Mask_RCNN/requirements.txt\"\n",
    "    shutil.copy(\"/content/drive/MyDrive/ISIC 2018 Dataset/model.py\",\"/content/mrcnn\")\n",
    "    shutil.copy(\"/content/drive/MyDrive/ISIC 2018 Dataset/saving.py\",\"/tensorflow-1.15.2/python3.7/keras/engine\")\n",
    "    shutil.rmtree(\"/content/Mask_RCNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5CIiSE2vcT5"
   },
   "source": [
    "# **Imports and Path Initializations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87758,
     "status": "ok",
     "timestamp": 1625871747227,
     "user": {
      "displayName": "Youssef Shaarawy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLBVF6e64J1Txhz0Btn0OOVi4soQV6cBHoy2AxCmo=s64",
      "userId": "04839140160760119561"
     },
     "user_tz": -120
    },
    "id": "742UV1r3ctLa",
    "outputId": "28a05b86-fa20-4a1a-fed8-55ebd72b67ca"
   },
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn import utils\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "# initialize the dataset path, images path, and masks file path\n",
    "DATASET_PATH = os.path.abspath(\"/content/drive/My Drive/ISIC 2018 Dataset\")\n",
    "\n",
    "# initialize the class names dictionary\n",
    "CLASS_NAMES = {1: \"lesion\"}\n",
    "\n",
    "# initialize the name of the directory where logs and output model\n",
    "# snapshots will be stored\n",
    "LOGS_AND_MODEL_DIR = \"drive/My Drive/ISIC 2018 Dataset/lesions_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1625852554896,
     "user": {
      "displayName": "Youssef Shaarawy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLBVF6e64J1Txhz0Btn0OOVi4soQV6cBHoy2AxCmo=s64",
      "userId": "04839140160760119561"
     },
     "user_tz": -120
    },
    "id": "ptfqghKYcvjV"
   },
   "outputs": [],
   "source": [
    "class LesionConfig(Config):\n",
    "\t# give the configuration a recognizable name\n",
    "\tNAME = \"lesion\"\n",
    "\n",
    "\t# set the number of GPUs to use training along with the number of\n",
    "\t# images per GPU (which may have to be tuned depending on how\n",
    "\t# much memory your GPU has)\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 6\n",
    "\n",
    "\t# set the number of steps per training epoch and validation cycle\n",
    "\tSTEPS_PER_EPOCH = train_size // (IMAGES_PER_GPU * GPU_COUNT)\n",
    "\tVALIDATION_STEPS = val_size // (IMAGES_PER_GPU * GPU_COUNT)\n",
    "\n",
    "\t# number of classes (+1 for the background)\n",
    "\tNUM_CLASSES = len(CLASS_NAMES) + 1\n",
    "\n",
    "\tIMAGE_MIN_DIM = 512\n",
    "\tIMAGE_MAX_DIM = 512\n",
    "\tRPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
    "\n",
    "class LesionBoundaryInferenceConfig(LesionConfig):\n",
    "\t# set the number of GPUs and images per GPU (which may be\n",
    "\t# different values than the ones used for training)\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 8\n",
    "\n",
    "\t# set the minimum detection confidence (used to prune out false\n",
    "\t# positive detections)\n",
    "\tDETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "class LesionDataset(utils.Dataset):\n",
    "\tdef __init__(self, imagePaths, masksPath, classNames, width=512):\n",
    "\t\t# call the parent constructor\n",
    "\t\tsuper().__init__(self)\n",
    "\n",
    "\t\t# store the image paths and class names along with the width\n",
    "\t\t# we'll resize images to\n",
    "\t\tself.imagePaths = imagePaths\n",
    "\t\tself.masksPath = masksPath\n",
    "\t\tself.classNames = classNames\n",
    "\t\tself.width = width\n",
    "\n",
    "\tdef load_lesions(self, idxs):\n",
    "\t\t# loop over all class names and add each to the 'lesion'\n",
    "\t\t# dataset\n",
    "\t\tfor (classID, label) in self.classNames.items():\n",
    "\t\t\tself.add_class(\"lesion\", classID, label)\n",
    "   \n",
    "    # loop over the image path indexes  \n",
    "\t\tfor i in range(idxs):\n",
    "    # extract the image filename to serve as the unique\n",
    "    # image ID\n",
    "\t\t\timagePath = self.imagePaths[i]\n",
    "\t\t\tfilename = imagePath.split(os.path.sep)[-1]\n",
    "      # add the image to the dataset\n",
    "\t\t\tself.add_image(\"lesion\", image_id=filename,path=imagePath)\n",
    "            \n",
    "\tdef load_image(self, imageID):\n",
    "\t\t# grab the image path, load it, and convert it from BGR to\n",
    "\t\t# RGB color channel ordering\n",
    "\t\tp = self.image_info[imageID][\"path\"]\n",
    "\t\timage = cv2.imread(p)\n",
    "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\t\t# resize the image, preserving the aspect ratio\n",
    "\t\timage = imutils.resize(image, width=self.width)\n",
    "\n",
    "\t\t# return the image\n",
    "\t\treturn image\n",
    "\n",
    "\tdef load_mask(self, imageID):\n",
    "\t\t# grab the image info and derive the full annotation path\n",
    "\t\t# file path\n",
    "\t\tinfo = self.image_info[imageID]\n",
    "\t\tfilename = info[\"id\"].split(\".\")[0]\n",
    "\t\tannotPath = os.path.sep.join([self.masksPath,\n",
    "\t\t\t\"{}_segmentation.png\".format(filename)])\n",
    "\n",
    "\t\t# load the annotation mask and resize it, *making sure* to\n",
    "\t\t# use nearest neighbor interpolation\n",
    "\t\tannotMask = cv2.imread(annotPath)\n",
    "\t\tannotMask = cv2.split(annotMask)[0]\n",
    "\t\tannotMask = imutils.resize(annotMask, width=self.width,\n",
    "\t\t\tinter=cv2.INTER_NEAREST)\n",
    "\t\tannotMask[annotMask > 0] = 1\n",
    "\n",
    "\t\t# determine the number of unique class labels in the mask\n",
    "\t\tclassIDs = np.unique(annotMask)\n",
    "\n",
    "\t\t# the class ID with value '0' is actually the background\n",
    "\t\t# which we should ignore and remove from the unique set of\n",
    "\t\t# class identifiers\n",
    "\t\tclassIDs = np.delete(classIDs, [0])\n",
    "\n",
    "\t\t# allocate memory for our [height, width, num_instances]\n",
    "\t\t# array where each \"instance\" effectively has its own\n",
    "\t\t# \"channel\" -- since there is only one lesion per image we\n",
    "\t\t# know the number of instances is equal to 1\n",
    "\t\tmasks = np.zeros((annotMask.shape[0], annotMask.shape[1], 1),\n",
    "\t\t\tdtype=\"uint8\")\n",
    "\n",
    "\t\t# loop over the class IDs\n",
    "\t\tfor (i, classID) in enumerate(classIDs):\n",
    "\t\t\t# construct a mask for *only* the current label\n",
    "\t\t\tclassMask = np.zeros(annotMask.shape, dtype=\"uint8\")\n",
    "\t\t\tclassMask[annotMask == classID] = 1\n",
    "\n",
    "\t\t\t# store the class mask in the masks array\n",
    "\t\t\tmasks[:, :, i] = classMask\n",
    "\n",
    "\t\t# return the mask array and class IDs\n",
    "\t\treturn (masks.astype(\"bool\"), classIDs.astype(\"int32\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlLUF8ihosrd"
   },
   "source": [
    "# `TESTING`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23701,
     "status": "ok",
     "timestamp": 1625852578588,
     "user": {
      "displayName": "Youssef Shaarawy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLBVF6e64J1Txhz0Btn0OOVi4soQV6cBHoy2AxCmo=s64",
      "userId": "04839140160760119561"
     },
     "user_tz": -120
    },
    "id": "Iw9rW_w4JnaB",
    "outputId": "d02af9cd-9d7b-445e-86a2-102572930fdc"
   },
   "outputs": [],
   "source": [
    "from cv2 import imshow\n",
    "  # initialize the inference configuration\n",
    "config = LesionBoundaryInferenceConfig()\n",
    "\n",
    "\t\t# initialize the Mask R-CNN model for inference\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "\tmodel_dir=LOGS_AND_MODEL_DIR)\n",
    "\n",
    "\t\t# load our trained Mask R-CNN\n",
    "weights = model.find_last()\n",
    "model.load_weights(weights, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 85754,
     "status": "error",
     "timestamp": 1623087406555,
     "user": {
      "displayName": "Youssef Shaarawy",
      "photoUrl": "",
      "userId": "04839140160760119561"
     },
     "user_tz": -120
    },
    "id": "3C_JGm1PouEo",
    "outputId": "6f936dd8-b479-4e51-e7cb-e1cca053f1d2"
   },
   "outputs": [],
   "source": [
    "TEST_PATH = os.path.sep.join([DATASET_PATH,\n",
    "\t\"Test\"])\n",
    "TEST_PATHS = sorted(list(paths.list_images(TEST_PATH)))\n",
    "images=['']*config.BATCH_SIZE\n",
    "passes = (len(TEST_PATHS)//config.BATCH_SIZE) +1\n",
    "for k in range(0,passes):\n",
    "\tfor i in range(0,config.BATCH_SIZE):\n",
    "\t\tif not (config.BATCH_SIZE*k + i>=len(TEST_PATHS)):\n",
    "\t\t\timage = cv2.imread(TEST_PATHS[config.BATCH_SIZE*k+i])\n",
    "\t\t\timage = imutils.resize(image, width=512)\n",
    "\t\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\t\t\timages[i]=image\n",
    "\t# perform a forward pass of the network to obtain the results\n",
    "\tresult = model.detect(images, verbose=1)\n",
    "\tfor j in range(0,len(result)):\n",
    "\t\tr=result[j]\n",
    "\t# loop over the predicted scores\n",
    "\t\tmaxScore= 0\n",
    "\t\tfor i in range(0, len(r[\"scores\"])):\n",
    "\t\t# extract the bounding box information, class ID, label,\n",
    "\t\t# and predicted probability from the results\n",
    "\t\t\tif r[\"scores\"][i]>maxScore:\n",
    "\t\t\t\tmaxScore=r[\"scores\"][i]\n",
    "\t\t\t\t(startY, startX, endY, endX) = r[\"rois\"][i]\n",
    "\t\tfor i in range(0, r[\"rois\"].shape[0]):\n",
    "\t\t\tmask = r[\"masks\"][:, :, i]\n",
    "\n",
    "\t\t\timage = images[j]\n",
    "\t\t\timage = visualize.draw_box(image, r[\"rois\"][i],\n",
    "\t\t\t(1.0, 0.0, 0.0))\n",
    "\t\timage = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\t\t# loop over the predicted scores and class labels\n",
    "\t\tfor i in range(0, len(r[\"scores\"])):\n",
    "\t\t\t# extract the bounding box information, class ID, label,\n",
    "\t\t\t# and predicted probability from the results\n",
    "\t\t\t(startY, startX, endY, end) = r[\"rois\"][i]\n",
    "\t\t\tclassID = r[\"class_ids\"][i]\n",
    "\t\t\tlabel = CLASS_NAMES[classID]\n",
    "\t\t\tscore = r[\"scores\"][i]\n",
    "\n",
    "\t\t\t# draw the score on the image\n",
    "\t\t\ttext = str(score)\n",
    "\t\t\ty = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\t\t\tcv2.putText(image, text, (startX, y),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "\t\t# resize the image so it more easily fits on our screen\n",
    "\t\timage = imutils.resize(image, width=256)\n",
    "\n",
    "\t\t# show the output image\n",
    "\t\tcv2_imshow(image)\t \n",
    "\tprint(str(k*100//passes)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B1MVHXu1NJD"
   },
   "source": [
    "# **Lesion Segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1625871894205,
     "user": {
      "displayName": "Youssef Shaarawy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLBVF6e64J1Txhz0Btn0OOVi4soQV6cBHoy2AxCmo=s64",
      "userId": "04839140160760119561"
     },
     "user_tz": -120
    },
    "id": "1XZGJS2Z1Rni",
    "outputId": "876e9802-b8f5-490f-f75f-1f5751286970"
   },
   "outputs": [],
   "source": [
    "TEST_PATH = \"/content/drive/MyDrive/ISIC 2019 Dataset/TrainingAugmented\"\n",
    "TEST_PATHS = [f for f in sorted(paths.list_images(TEST_PATH))]\n",
    "len(TEST_PATHS)\n",
    "images=['']*config.BATCH_SIZE\n",
    "passes = (len(TEST_PATHS)//config.BATCH_SIZE) +1\n",
    "for k in range(0,passes):\n",
    "\tfor i in range(0,config.BATCH_SIZE):\n",
    "\t\tif not (config.BATCH_SIZE*k + i>=len(TEST_PATHS)):\n",
    "\t\t\timage = cv2.imread(TEST_PATHS[config.BATCH_SIZE*k+i])\n",
    "\t\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\t\t\timages[i]=image\n",
    "\t# perform a forward pass of the network to obtain the results\n",
    "\tresult = model.detect(images, verbose=1)\n",
    "\tfor j in range(0,len(result)):\n",
    "\t\tr=result[j]\n",
    "\t# loop over the predicted scores\n",
    "\t\tmaxScore= 0\n",
    "\t\tfor i in range(0, len(r[\"scores\"])):\n",
    "\t\t# extract the bounding box information, class ID, label,\n",
    "\t\t# and predicted probability from the results\n",
    "\t\t\tif r[\"scores\"][i]>maxScore:\n",
    "\t\t\t\tmaxScore=r[\"scores\"][i]\n",
    "\t\t\t\t(startY, startX, endY, endX) = r[\"rois\"][i]\n",
    "\t\tif not config.BATCH_SIZE*k + j>=len(TEST_PATHS):\n",
    "\t\t\tif maxScore>0:\n",
    "\t\t\t\timagePath = TEST_PATHS[config.BATCH_SIZE*k + j]\n",
    "\t\t\t\timageName = os.path.basename(imagePath)\n",
    "\t\t\t\tim = Image.open(imagePath)\n",
    "\t\t\t\twidth, height = im.size\n",
    "\t\t\t\tbox = (startX, startY, endX, endY)\n",
    "\t\t\t\tcrop = im.crop(box)\n",
    "\t\t\t\tcrop.save('/content/drive/MyDrive/ISIC 2019 Dataset/ISIC_2019_Training_Input/'+imageName, 'JPEG')\n",
    "\t\t\telse:\n",
    "\t\t\t\timagePath = TEST_PATHS[config.BATCH_SIZE*k + j]\n",
    "\t\t\t\timageName = os.path.basename(imagePath)\n",
    "\t\t\t\tshutil.copy(imagePath,'/content/drive/MyDrive/ISIC 2019 Dataset/ISIC_2019_Training_Input/'+imageName)\n",
    "\tprint(str(k*100//passes)+'%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPFbDOYZ5K3GH7+PYfUTbVd",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1itmxnwApxPq-CuPwBztC7lYJSuSrXQHn",
   "name": "Lesion Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
